# 1 计算机系统结构的基本概念
##  1.2 计算机系统结构的概念
- 计算机系统的多级层次结构：

  - L1微程序机器级
  - L2机器语言（传统机器级）
  - L3操作系统虚拟机
  - L4汇编语言虚拟机
  - L5高级语言虚拟机
  - L6应用语言虚拟机

  每一层以一种语言为特征，包括：微程序语言、机器语言、汇编语言、高级语言、应用语言（如SQL）。

  通常L1-L3级是用**解释**的方法实现，L4-L6级则是用**翻译**的方法实现。

  L1-L2属于硬件层面，L3-L6属于软件层面。

- 虚拟机：由软件实现的机器。

- 翻译：先把L+1级程序全部变换成L级程序后，再去执行新产生的L级程序。

  解释：每当一条L+1级指令被译码后，就直接去执行一串等效的L级指令，然后再去取一条L+1级的指令。

- 计算机系统结构：由程序员看到的计算机属性，即**概念性结构**与**功能特性**。

  计算机组成：**计算机系统结构**的逻辑实现。

  计算机实现：**计算机组成**的物理实现。

  【计算机**系统结构** --**逻辑**实现--> 计算机**组成** --**物理**实现--> 计算机**实现**】

- 计算机系统结构概念实质：确定计算机系统中软、硬件的界面。

- 广义系统结构（设计的三个方面）：指令集结构、组成、硬件。
- 通用寄存器型机器系统结构的属性：指令系统、数据表示、寻址规则、寄存器定义、中断系统、机器工作状态的定义和切换、存储系统、信息保护、I/O结构。（由L2级完成）

- 透明性：本来存在的事物或属性从某种角度看又好像不存在。

- 计算机系统结构的分类：
  - 冯氏分类法：用**最大并行度**进行分类。

  - Flynn分类法：按照**指令流**和**数据流**的**多倍性**分为4类：

    - 单指令流单数据流SISD
    - 单指令流多数据流SIMD
    - 多指令流单数据流MISD
    - 多指令流多数据流MIMD

    指令流：计算机执行的指令序列。

    数据流：由指令流调用的数据序列。

    多倍性：在系统受限的部件上，同时处于同一执行阶段的指令或数据的最大数目。

## 1.3 定量分析技术
- 计算机系统设计常用的4个定量原理：以经常性事件为重点、Amdahl定律、CPU性能公式、程序的局部性原理。

- Amdahl定律：

  $加速比 = \frac{总执行时间_{改进前}}{总执行时间_{改进后}} = \frac{1}{(1-可改进比例)+\frac{可改进比例}{部件加速比}}$

  加速比依赖于两个因素：可改进比例、部件加速比。

- CPU性能公式：
  
  $CPU时间 = IC \times CPI \times 时钟周期时间$

  CPU性能取决于三个参数（相互制约）：
  - 时钟周期时间：取决于硬件实现技术和计算机组成
  - CPI：每条指令的平均时钟周期数，取决于计算机组成和指令集结构

    $CPI = \frac{总时钟周期数}{IC}$

  - IC：所执行的指令条数，取决于指令集结构和编译技术

- 程序的局部性原理：程序执行时访问的存储器地址分布不是随机的，而是相对簇聚。（局部性包括时间局部性和空间局部性）

- 计算机系统性能评测标准：
  - 执行时间：执行单个程序所花时间
  - 吞吐率：单位时间里能够完成的任务量

## 1.4 计算机系统结构的发展
- 冯·诺依曼结构：由运算器、控制器、存储器、输入设备和输出设备构成的存储程序式计算机。
  
  主要特点：
  1. 计算机以运算器为中心
  2. 在存储器中指令和数据同等对待
  3. 存储器按地址访问，顺序线性编址，每个单元的位数固定
  4. 指令顺序执行
  5. 指令由操作码和地址码组成
  6. 指令和数据均以二进制编码表示，采用二进制运算
  
  后来的改进：
  1. 输入输出方式改进
  2. 采用并行处理技术
  3. 存储器组织结构的发展
  4. 指令集的发展（CISC/RISC）


- 存储程序原理的基本点是**指令驱动**

- 系列机：同厂家，系统结构相同、组成和实现不同（根本特征：向后兼容）
  
  兼容机：不同厂家，系统结构相同

- 系列机的软件兼容
  - 向上下兼容：高档/低档
  - 向前后兼容：投入市场时间
  
  兼容指不加修改就能运行。

- 模拟：用软件方法实现另一台机指令集
  
  仿真：用微程序解释实现另一台机指令集

## 1.5 计算机系统结构中并行性的发展
- 并行性：两个或以上的事件在同一时刻发生
  
  并发性：两个或以上的事件在同一时间间隔内发生

- 并行性等级

  处理数据角度：
  1. 字串位串
  2. 字串位并
  3. 字并位串
  4. 全并行

  执行程序角度：
  1. 指令内部并行
  2. 指令级并行
  3. 线程级并行
  4. 任务级或过程级并行
  5. 作业或程序级并行

- 提高并行性的三种途径：时间重叠（流水线）、资源重复、资源共享（分时系统）

- 耦合度：反映**物理连接紧密程度**和**交互作用能力强弱**
  
  紧密耦合系统：通过**总线或高速开关**互连，共享**主存**
  
  松散耦合系统：通过**通道或通信线路**互连，共享**外存**

- 异构型多处理机：由负担**不同**功能的处理机组成（**时间重叠**）

  同构型多处理机：由负担**相同**功能的处理机组成（**资源重复**）

# 2 计算机指令集结构
## 2.1 指令集结构的分类
- 指令集结构分类（根据存储操作数的存储单元划分）：堆栈结构、累加器结构、通用寄存器结构

## 2.3 指令集结构的功能设计
- CISC指令集结构的问题：
  1. 指令使用频率差距大
  2. 指令集庞大，指令功能复杂
  3. 指令执行速度慢
  4. 规整性不好，不利于流水线

- RISC设计原则：
  1. 指令条数少而简单
  2. 采用简单而统一的指令格式，并减少寻址方式
  3. 指令执行在单个机器周期完成
  4. 只有load和store指令才能访问存储器
  5. 大多指令用硬连逻辑实现
  6. 强调优化编译器的优化作用
  7. 充分利用流水线

# 3 流水线技术
## 3.1 流水线的基本概念
- 流水线技术：把多个**处理过程**在时间上**错开**，依次通过各功能段，使子过程间**并行**进行。
  
  流水线的深度：流水线段数

  流水线技术的特点：合作、瓶颈、流水寄存器、适用于大量重复、通过时间和排空时间。

- 流水线分类
  - 单功能流水线（固定功能）、多功能流水线（各段不同连接可以完成不同功能）
  - 静态流水线（同一时间连接方式和功能不变）、动态流水线（同一时间连接方式和功能可以变化）
  - 部件级流水线（运算部件分段）、处理机流水线（指令执行分段）、处理机间流水线（分处理机）
  - 线性流水线（串行连接）、非线性流水线（串行+反馈回路）
  - 顺序流水线（输入输出顺序一致）、乱序流水线（输入输出顺序可以不同）

## 3.2 流水线的性能指标
- 流水线性能指标
  - 吞吐率：$TP = \frac{n}{T_{K}} = \frac{n}{(k+n-1)\Delta t}$
  
    $n$为任务数，$T_{K}$为完成任务的时间\
    最大吞吐率与时间最长的段决定

  - 加速比：$S = \frac{T_{s}}{T_{k}} = \frac{nk}{k+n-1}$
  
    最大加速比为k

  - 效率：$E = \frac{n个任务实际占用时空区}{k个段总时空区}$
  
    通过时空图来计算

- 流水线设计中的问题
  - 瓶颈问题
  - 流水线额外开销：流水寄存器延迟和时钟偏移开销
  - 冲突问题

- 解决流水线瓶颈问题：细分瓶颈段、重复设置瓶颈段

- 画时空图计算流水线指标
  1. 确定一个合适的算法（计算执行顺序）
  2. 画出时空图（注意是静态流水线还是动态流水线）
  3. 计算效率

## 3.3 流水线的相关与冲突
- 经典5段流水线

  分支指令需要2或4个周期、store指令需要4个周期，其他指令需要5个周期

  需要解决：
    1. 避免IF段的访存和MEM段的访存发生结构冲突：分离指令存储器（Cache）和数据存储器（Cache）
    2. 避免ID段和WB段访问同一寄存器：把时钟周期分为前写后读两部分

- 相关：两条指令之间存在某种依赖关系。

- 相关分类
    - 数据相关：写后读，具有传递性
    - 名相关：包括**反相关**（读后写）和**输出相关**（写后写）
    - 控制相关：由分支指令引起的相关

- 换名技术：通过改变指令中操作数的名来消除名相关，如寄存器换名。

- 流水线冲突
  - 结构冲突：硬件资源满足不了指令重叠执行的要求

    【有时为了减少硬件成本会允许结构冲突的存在】

  - 数据冲突：后方指令需要用到前面指令的执行结果（不一定是数据相关）
    - 写后读（RAW）冲突：读到了旧值
    - 写后写（WAW）冲突：旧值覆盖了新值
    - 读后写（WAR）冲突：读到了新值

  - 控制冲突：流水线遇到分支指令等会改变PC值的指令

- 数据冲突的解决
  - 定向技术：在某条指令产生计算结果之前，其他指令并不真正立即需要该结果，如果能将结果从产地直接送到需求处（不等写回），就可以避免停顿，解决**写后读**冲突。
  - 插入停顿气泡：流水线互锁机制。
  - 指令调度（流水线调度）：编译器调度指令顺序。

- 控制冲突的解决
  - 排空流水线，产生**分支延迟**
  - 通过软件（编译器）**静态**减少分支延迟
    - 预测分支失败：预测错则转为空操作
    - 预测分支成功：一旦计算出目标地址就跳转（适用于判断是否分支在计算目标地址之后）
    - 延迟分支：在分支指令后加上**延迟槽**（绝大多数是一条指令）

      调度延迟槽指令的方法有3种：
        - 从前调度（首选）：把分支指令前的无关指令**移动**到分支指令后方。
        - 从目标处调度（预测成功）：把分支目标处的指令**复制**到分支指令后方，并改变分支目标地址。
        - 从失败处调度（预测失败）：将分支指令后方作为延迟槽。
  
        复制：从别的路径可能也要执行到该指令。有可能增大程序空间。
        分支取消：预测错则转为空操作

## 3.4 流水线的实现
- 流水寄存器的作用
  1. 将各段的工作隔开，防止互相干扰
  2. 保存相应段的结果
  3. 向后传递数据或控制信息

- MIPS流水线各段操作

  1. 取指周期（IF）：
     - 取指令
     - 根据分支条件更新PC和NPC

  2. 译码/读寄存器周期（ID）：
     - 取操作数
     - 符号位扩展并传递立即数
     - 传递IR和NPC

  3. 执行/有效地址计算周期（EX）：
     - 计算地址
     - 判断分支结果
     - 传递IR和B

  4. 存储器访问/分支完成周期（MEM）：
     - 读写存储器
     - 传递ALUo和IR

  5. 写回周期（WB）：
     - 将结果写回寄存器

# 4 指令级并行
## 4.1 指令集并行的概念
- 指令级并行（ILP）：指令之间存在的潜在并行性。

- 程序基本块：一串除了出入口外没有分支和转入的连续代码。

- IPC：CPI的倒数，每个时钟周期完成的指令数

- 循环级并行：使一个循环中的不同循环体并行执行。
  
  实现方法包括**循环展开**和采用**向量表示**指令和数据。

- 正确执行程序需要保持的两个属性：**数据流**和**异常行为**。

  保持异常行为常弱化为：指令执行顺序的改变不能导致发生新的异常。

- 不精确异常：发生异常时的现场不同。

  即使保持异常，动态调度也可能发生不精确异常。

## 4.2 指令的动态调度
- 静态调度与动态调度
  - 静态调度：流水线依靠编译器在**编译期间**调度代码，通过把相关指令距离拉开来减少停顿。
  - 动态调度：依靠专门硬件，在**程序执行过程中**调度代码。
  
    动态调度的优点：
    - 能够处理编译时情况不明的相关，并简化了编译器
    - 能够使本来使面向某一流水线优化编译的代码在其他流水线上也能高效执行。

    动态调度的缺点：
    - 硬件复杂度显著增加

- 动态调度的基本思想
  - 将译码分为两个阶段
    - **流出**：译码、检查结构冲突
    - **读操作数**：等待数据冲突消失后读操作数

- Tomasulo算法：一种动态调度算法，记分牌算法的改进。
  - 基本思想
    - 操作数一旦就绪就立即执行，尽可能减少RAW冲突
    - 使用寄存器换名消除WAR冲突和WAW冲突

  - 特点
    - 冲突检测和指令执行控制是分布的
    - 计算结果通过CBD直达而不经过寄存器

  - 优点
    - 冲突检测逻辑是分布的
    - 消除了WAW和WAR冲突导致的停顿

- MIPS处理器浮点部件结构
  - 保留站：设置在运算部件入口，保存一条已流出并等待执行的指令信息。

  - 公共数据总线CDB：一条重要的数据通路，接收所有功能部件的计算结果并播送到需要的地方。
  
    【多流出流水线需要多条CDB】

  - load缓冲器和store缓冲器：存放读写存储器的数据或地址，类似保留站。

  - 浮点寄存器
  - 指令队列
  - 运算部件

- Tomasulo算法流程
  1. 流出

     【进入条件：申请保留站（结构冲突）】\
     运算指令：找两个操作数-预约目的寄存器\
     load指令：找第一操作数-符号位扩展立即数-预约目的寄存器\
     store指令：找两个操作数-预约目的寄存器

  2. 执行
    
     【进入条件：操作数就绪/到达缓冲队列头部】\
     运算指令：进行计算\
     load指令：计算有效地址-读存储器\
     store指令：计算有效地址

  3. 写结果

     【进入条件：执行结束/CBD就绪】\
     运算指令：写回寄存器-送到其他保留站\
     load指令：写回寄存器-送到其他保留站\
     store指令：写入存储器

- 保留站字段
  - Op：操作类型
  - Qj, Qk：产生操作数的保留站号，已产生则为0
  - Vj, Vk：操作数
  - Busy：yes/no表示是否在用
  - A：**load/store缓冲器特有**，先存放立即数，后存放有效地址

- 寄存器状态表
  - Qi：将为每个寄存器送来数据的保留站号，为0代表数据已就绪

## 4.3 动态分支预测技术
- 动态分支预测：在程序运行时，根据分支指令过去的表现来预测其将来的行为。

- 分支历史表BHT：也叫分支预测缓冲器，常用两位分支预测。最简单：分支预测、状态修改。

- 分支目标缓冲器BTB：专门硬件实现的一张表格，包含**执行过的成功分支指令地址**和**预测的分支目标地址**。
  
  如果第一字段匹配，则用第二字段替换PC，否则当作非分支指令（预测失败）。

  另一形式：在BTB中存放若干条目标处指令。

- 前瞻执行：猜测结果并提前执行，但结果存入ROB，确认后写回。

  特点
    - 乱序执行、顺序确认
    - 实现精确异常
    - 硬件复杂度高

- ROB缓冲器字段
  - 指令类型
  - 目标地址：寄存器号或存储器地址（store）
  - 数据值
  - 数据是否就绪

## 4.4 多指令流出技术
- 多流出处理机两种基本风格：超标量、超长指令字。

## 4.5 循环展开和指令调度
- 展开直到消除停顿

# 5 存储系统
## 5.1 存储系统的层次结构
- 存储系统追求指标：**容量**大、**速度**快、**价格**低

- Cache-主存”层次和“主存-辅存”层次
  |                       | Cache-主存”层次 | “主存-辅存”层次 |
  | --------------------- | --------------- | --------------- |
  | 目的                  | 弥补主存速度    | 弥补主存容量    |
  | 实现                  | 主要由硬件      | 主要由软件实现  |
  | 速度和大小差距        | 小              | 大              |
  | CPU对第二级的访问方式 | 直接访问        | 通过第一级      |
  | 不命中时CPU是否切换   | 否              | 是              |

## 5.2 Cache基本知识
- 全相联映像：主存中的任一块可以被放置到Cache中的任一位置。
  
  直接映像：主存中的每一个块只能被放置到Cache中的唯一位置。

  组相联映像：主存中的每一块可以被放置到Cache中唯一组中的任一位置。

- 索引：组相联映像和直接映像中Cache的组或位置。

- 相联度：组相联映像中每组的块数。相联度越高，**Cache空间利用率**就越高，**块冲突概率**就越低，**命中率**就越高。但n越高不一定性能越好，反而还会增加Cache实现复杂度。

- 主存地址：标识（唯一确定块） + 索引 + 块内位移。

- 目录表：目录项与Cache块一一对应，记录对应的主存块信息。

- 查找算法：并行查找、顺序查找

- 替换算法：随机法（实现简单）、FIFO、LRU（命中率高）

- 写策略
  - 写直达法：把数据写入Cache的同时也写回下一级存储器。**优点：易于实现，一致性好**。
  - 写回法：只把数据写入Cache，不写入存储器；只有在Cache块被替换时才写回下一级存储器。**优点：速度快、带宽要求低**。

- 写不命中处理方法：
  - 按写分配法：先把块调入Cache再写。配合**写回法**。
  - 不按写分配法：直接写入下一级存储器而不将块调入Cache。配合**写直达法**。

- Cache性能指标
  - 不命中率
  - 平均访存时间
  
    $平均访存时间 = 命中时间 + 不命中率 \times 不命中开销$

  - 程序执行时间
  
    $CPU时间 = (CPU执行周期数 + 存储器停顿周期数) \times 时钟周期时间$\
    $CPU时间 = IC \times (CPI_{exec} + 平均访存次数 \times 不命中率 \times 不命中开销) \times 时钟周期时间$

- Cache性能改进：降低**不命中率**、减少**不命中开销**、减少**命中时间**

## 5.3 降低Cache不命中率
- 三种不命中
  - 强制性不命中：首次访问未调入。与**块大小**有关。
  - 容量不命中：容量不足被替换。与**容量**有关。
  - 冲突不命中：组冲突被替换。与**相联度**有关。

- 增加**Cache块大小**
  - 不命中率**先减后增**
  - 会增加**不命中开销**

- 增加**Cache容量**
  - 会增加**成本**
  - 可能增加**命中时间**

- 提高**相联度**
  - 相联度超过8意义不大
  - 2:1 Cache经验规则：容量为N的直接映像和容量为N/2的两路组相联不命中率差不多。
  - 会增加**命中时间**

- 伪相联Cache：最高位取反作为伪相联组，找两次。兼具组相联的**低不命中率**和直接映像的**高命中速度**。

- 硬件预取：指令和数据。

- 编译器控制的预取：寄存器预取/Cache预取、故障性预取/非故障性预取（故障是否引发异常）

- 牺牲Cache：增设全相联Cache存放被替换的块。

- 编译优化：无需改动硬件，重组程序的代码和数据
  - 数组合并：提高访问局部性
  - 内外循环交换：交换循环的嵌套关系，使程序按存储顺序访问数据
  - 循环融合：在替换前反复使用相同数据
  - 分块：把对数组整行整列的访问改为对块进行

## 5.4 减少Cache不命中开销
- 采用两级Cache：在一级Cache与主存间增设二级Cache。
- 让读不命中优先于写：在读不命中时直接检查写缓冲器的内容而不写回主存。
- 写缓冲合并：写入操作若与写缓冲器某项地址匹配，则与该项合并。
- 请求字处理技术：当CPU请求的字到达后，不等整块都调入Cache就可以把该字发送。
  - 尽早重启动：一调入请求字就让CPU重启动
  - 请求字优先：让存储器先提供请求字
- 非阻塞Cache技术：Cache在不命中时仍能处理部分访问，让CPU在等待Cache给出数据的同时继续执行后面的指令。

## 5.5 减少命中时间
- 容量小、结构简单的Cache
- 虚拟Cache：可以直接用虚拟地址访问的Cache，命中时不需要地址转换，不命中时地址转换和Cache访问并行进行。
- Cache访问流水化：把对第一级Cache的访问按流水方式组织。
- 踪迹Cache：存放CPU执行的动态指令序列，包含分支预测展开了的指令。只存放转入位置到转出位置之间的指令。

## 5.6 并行主存系统
- 并行主存系统：在一个访存周期内能并行访问多个存储字的存储器（提高带宽）。
- 并行存储器结构
  - 单体多字存储器：实现简单；访存效率不高
  - 多体交叉存储器：高位交叉编址 + 低位交叉编址

- 体冲突：两个访问请求要访问同一存储体。

# 6 输入/输出系统
- 数据不一致问题
  - Cache新，存储器旧：写直达
  - Cache旧，存储器新：作废Cache

## 6.1 输入/输出系统的性能
- 响应时间：从用户键入命令开始到得到结果所花的时间。

- MTTF：平均失效前时间
  
  $失效率 = \frac{1}{MTTF}$

  系统失效率：所有部件失效率相加

## 6.2 输入/输出系统的可靠性、可用性和可信性
- 可靠性：系统一直连续提供服务的能力。

  可用性：系统正常工作的时间在两次正常服务间隔时间中所占的比率。

  可信性：服务的质量。

- 提高系统组成部件可靠性的方法：有效构建方法、纠错方法

## 6.3 廉价磁盘冗余阵列RAID
- 磁盘阵列：使用多个磁盘的组合来代替一个大容量磁盘。

- 廉价磁盘冗余阵列：存放冗余信息以便磁盘信息丢失时进行恢复的磁盘阵列。

- RAID分级
  | RAID级别 | 名称                       | 说明                           |
  | -------- | -------------------------- | ------------------------------ |
  | RAID0    | 非冗余磁盘阵列             | 条带存放，没有纠错能力         |
  | RAID1    | 镜像磁盘                   | 复制一份，成本高               |
  | RAID2    | 存储器式磁盘阵列           | 利用Hamming纠错码，代价为log级 |
  | RAID3    | 位交叉奇偶校验磁盘阵列     | 空间开销为1，大规模读写带宽高  |
  | RAID4    | 块交叉奇偶校验磁盘阵列     | 空间开销为1，小规模读写带宽高  |
  | RAID5    | 块交叉分布奇偶校验磁盘阵列 | 空间开销为1，小规模读写带宽高  |
  | RAID6    | P+Q双校验磁盘阵列          | 能容忍2个故障，但空间开销为2   |

- RAID1+0和RAID0+1：RAID0和RAID1结合的结果
  
  RAID10：先进行镜像，然后再进行条带存放

  RAID01：先进行条带存放，然后再进行镜像

## 6.5 通道处理机
- 通道：专门负责整个计算机系统的输入/输出工作的专用处理机。

- 通道分类
  - 字节多路通道：以字节为宽度传送
  - 选择通道：一次传送一台外设数据
  - 数组多路通道：每次传送一台外设的定长块

- 通道流量：通道单位时间传送的数据量。

# 8 多处理机
## 8.1 引言
- 集中式共享多处理机：处理器个数较少，共享一个集中式物理存储器。也叫对称式。
  
  分布式共享多处理机：处理器个数较多，存储器分布到各个处理器上，要求高带宽的互联网络。

- 两种存储器系统结构和通信机制
  - 共享地址空间，统一编址 + 共享存储器通信机制
  - 独立地址空间，分别编址 + 消息传递通信机制

- 共享存储器通信机制优点
  - 与对称式多处理机机制兼容
  - 易编程，简化编译器
  - 采用共享存储模型开发
  - 数据量小时开销小，带宽利用好
  - 可采用Cache减少远程通信频度

- 消息传递通信机制优点
  - 硬件简单
  - 通信是显式的，通信时间和开销明确
  - 显式通信利于开发出结构性能更佳的程序
  - 同步与发送消息关联，减少错误可能

## 8.2 对称式共享存储器系统结构
- 多Cache一致性：如果允许共享数据进入Cache且多个处理器的Cache中都有同一存储块的副本，当某个副本被修改后就会与其他副本不一致。

- Cache一致性协议
  - 目录式协议：存储器数据块的共享状态保存在目录中。实现开销较大但可实现大规模。
  - 监听式协议：共享状态信息与数据块一起被调入Cache存放。Cache间通过共享存储器总线交换信息。

- 解决Cache一致性问题的写方法
  - 写作废协议（最常用、首选）：在处理器进行写入操作之前，把所有其他Cache中的副本全部作废。
  - 写更新协议：在处理器进行写入时，把该新数据广播给所有其他Cache进行更新。

- 监听协议
  - Invalidate：作废通知
  
  - 设置有效位、共享位

  - Cache数据块的状态：无效（I）、共享（S）、已修改（M）

## 8.3 分布式共享存储器系统结构
- 目录协议
  - 目录：一种集中的数据结构，对于存储器中每一块都设置一项，记录状态及哪些Cache中有副本等。

  - 位向量：记录哪些Cache中有副本。

  - 共享集：有副本的处理机集合。

  - 分布式目录：把存储器和目录一起分布到各节点中。

  - 本地节点：发出访问请求的节点。

  - 宿主节点：包含所访问存储单元和目录项的节点

  - 远程节点：拥有相应副本的节点，有可能就是宿主节点。

  - 目录存储块的状态：未缓冲（U）、共享（S）、独占（E）

- 目录的三种结构
  - 全映像目录：处理简单、速度快
  - 有限映像目录：提高可扩放性、减少空间占用
  - 链式目录：既不限制个数，又保持了可扩展性

## 8.4 同步
- 基本硬件原语
  - 原子交换：将一个存储单元的值和一个寄存器的值进行交换。
  - 测试并置定：测试一个单元的值，如果符合条件则修改。
  - 读取并加一：返回存储单元的值并自动增加该值。

## 8.5 同时多线程
- 实现多线程的两种方法
  - 细粒度多线程：在每条指令之间都能进行线程的切换，从而使线程交替执行。
  - 粗粒度多线程：线程切换只发生在时间较长的停顿出现的时候。

- 同时多线程技术：一种在多流出、动态调度处理器上同时开发TLP（线程级并行）和ILP（指令级并行）的技术。

# 9 机群系统
## 9.1 机群的基本结构
- 机群：一种价格低廉、易于构建、可扩放性极强的并行计算机系统，它由多台同构或异构的独立计算机通过高性能网络或局域网连接在一起，协同完成特定并行计算任务

- 单一系统映像：机群的一个重要特征，有4重含义：单一系统、单一控制、对称性、位置透明

## 9.2 机群的特点
- 机群的优点
  - 系统开发周期短
  - 可靠性高
  - 可扩放性强
  - 性价比高
  - 用户编程方便

- 机群的缺点
  - 维护工作量大
  - 维护费用高

## 9.3 机群的分类
- 高可用性机群：采用冗余机制，在系统中某些节点故障时仍能对外服务。

- 负载均衡机群：实时分配任务，提供与节点个数成正比的负载能力。

- 高性能机群：以降低高性能计算成本为主要目的。